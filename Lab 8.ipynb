{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Job1: Intelligence Analyst - Entry Level\n",
    "Company: NC4\n",
    "Description: Intelligence Analyst for NC4 in Merrifield, VA. Also working with the International Monitoring Centers (NIMC)\n",
    "[Job Website](https://www.indeed.com/cmp/NC4/jobs/Intelligence-Analyst-63198433d1cf563f?sjdu=QwrRXKrqZ3CNX5W-O9jEvShgg173eaGcqumhSWKwuDksYOkjgyFqrDMUWoB3VpBovFKPbFNPRD9jdmWu02ALGEQ5gTHecRETGIXzZQdjmjM&tk=1d6goi85n515e802&adid=6100457&vjs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlwt        \n",
    "from collections import Counter        \n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlwt        \n",
    "from collections import Counter        \n",
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "  \n",
    "book = xlwt.Workbook() # create a new excel file\n",
    "sheet_test = book.add_sheet('word_count') # add a new sheet\n",
    "i = 0\n",
    "sheet_test.write(i,0,'word') # write the header of the first column\n",
    "sheet_test.write(i,1,'count') # write the header of the second column\n",
    "sheet_test.write(i,2,'ratio') # write the header of the third column\n",
    "    \n",
    "with open('job_one_8.txt','r',encoding='utf-8', errors = 'ignore') as text_word: # define the location of your txt file\n",
    "     \n",
    "    # convert all the word into lower cases\n",
    "    # filter out stop words\n",
    "    word_list = [i for i in text_word.read().lower().split() if i not in stop]\n",
    "    word_total = word_list.__len__()\n",
    "     \n",
    "    count_result =  Counter(word_list)\n",
    "    for result in count_result.most_common(10):\n",
    "        i = i+1 \n",
    "        sheet_test.write(i,0,result[0])\n",
    "        sheet_test.write(i,1,result[1])\n",
    "        sheet_test.write(i,2,(result[1]/word_total))\n",
    "    \n",
    "book.save('Lab_8_job_one.xls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Job1: Undergraduate Internship/Co-op Program - Intelligence Analyst\n",
    "Company: CIA\n",
    "Description: Intelligence Analyst for CIA.\n",
    "[Job Website](https://www.indeed.com/viewjob?jk=59aa1e9758098a81&tk=1d6goi85n515e802&from=serp&vjs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlwt        \n",
    "from collections import Counter        \n",
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "  \n",
    "book = xlwt.Workbook() # create a new excel file\n",
    "sheet_test = book.add_sheet('word_count') # add a new sheet\n",
    "i = 0\n",
    "sheet_test.write(i,0,'word') # write the header of the first column\n",
    "sheet_test.write(i,1,'count') # write the header of the second column\n",
    "sheet_test.write(i,2,'ratio') # write the header of the third column\n",
    "    \n",
    "with open('job_two_8.txt','r',encoding='utf-8', errors = 'ignore') as text_word: # define the location of your txt file\n",
    "     \n",
    "    # convert all the word into lower cases\n",
    "    # filter out stop words\n",
    "    word_list = [i for i in text_word.read().lower().split() if i not in stop]\n",
    "    word_total = word_list.__len__()\n",
    "     \n",
    "    count_result =  Counter(word_list)\n",
    "    for result in count_result.most_common(10):\n",
    "        i = i+1 \n",
    "        sheet_test.write(i,0,result[0])\n",
    "        sheet_test.write(i,1,result[1])\n",
    "        sheet_test.write(i,2,(result[1]/word_total))\n",
    "    \n",
    "book.save('Lab_8_job_two.xls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wordcloud Image 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-66c802e04209>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-10-66c802e04209>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    <img src =\"wordcloud_job_one.png\">\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "<img src =\"wordcloud_job_one.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wordcloud Image 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<img src =\"wordcloud_job_two.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learn', 'cover', 'contribute', 'Writing', 'Our', 'Now', 'proficiencies.', 'three', 'able', 'NC4s', 'thrive', 'customized', '365', 'Strong', 'legal', 'ET', 'deadlines', 'highly', 'communication', 'natural', 'verbal', 'rotation', 'reliability', 'desire', 'potential', 'base.', 'Level', 'employee', 'disasters,', '15', 'beginning', 'Professionally', 'Merrifield,', 'management', 'PC', 'Responsibilities', 'languages', 'Specialized', 'mapping', 'operations', 'Entry', 'yearto', 'position:', 'monitor', 'Quickly', 'minimum', 'business', 'follow-up', 'Competencies', 'English', '3-to-5-days-on,', '7', 'place', 'civil', 'writing/research', 'which', 'Required', 'using', 'are', 'fields', 'Previous', 'AM', 'filtering', 'motivated', 'Purpose', 'responding', 'level', 'internet', 'follow', 'journalism,', 'night', 'make', 'Role:', 'broad', 'safety', '(NIMC)', 'management,', 'Geo-locating', 'Include', 'foreign-language', 'hours', 'Proficiency', 'Graveyard', 'Monitoring', 'emergency', 'logistics,', 'Essential', 'interest', 'unrest,', '3-to-5-days-off', 'Familiarity', 'multi-task', 'Analysts', 'incidents,', 'include', 'Conducting', 'feedback', 'independent', 'openings', 'decisions', 'School', 'Diploma', 'fires,', 'meet', 'research', 'fast-paced', 'detail', 'experience', 'sent', 'terrorist', 'schedule', 'How', 'incident', 'entry', 'out', 'centers', 'some', 'entry-level', 'government', 'domestic', 'organizational', 'taking', 'world', 'current', 'shift', 'Risk', 'alerts', 'weekends', 'Self-sufficient,', 'real-time', 'Analyst:', '5', 'travel', 'Be', 'procedural', 'health,', 'Must', 'could', 'inquiries', 'collaborative', 'framework', 'requirements', 'client', 'thousands', 'sources', 'ending', 'month,', 'operations.', 'Current', 'holidays.', 'hazmat,', 'Duties', 'transportation', 'support', 'impact', 'up', 'attention', 'accurate,', 'typically', 'incidents', 'consistency', 'years', 'software', 'open-source', 'Degree', 'media', 'ET.', 'all-hazards', 'environment', 'day,', 'corporate', 'security,', 'product.', 'information24', 'assessing', 'salary', 'disruptions,', 'initial', 'Superior', 'critical', 'roles', 'PM', 'Ability', 'includes', 'concise', 'team', 'skills.', 'High', 'related', 'right', 'affect', 'Preferred', 'based/emergency', 'meteorology,', 'letter', 'Knowledge', 'Centers', 'customer', 'short-term', 'continuity,', 'field.', 'NC4', 'affairs,', 'NIMC,', 'diverse', 'Key', 'skills', 'Bachelors', 'clients', 'accuracy'}\n",
      "{'Cybersecurity', 'accurate', '20005', 'Booz', 'technologiesand', 'Internship', 'emerging', '3.0', 'evaluating', 'action:', 'processing.', 'transformed', 'may', 'assess', '4-point', 'apply', 'nations', 'scale', 'schooling', 'evaluated', 'city,', 'into', 'drug', 'Agency', 'offers', 'proliferation,', 'national', 'career', 'hour', 'DA', 'eligible).', 'salaries', 'carefully', 'just', 'arts', \"it's\", 'happen.', 'LeidosMcLean,', 'OBP', 'majors,', 'leadership', 'oral', 'original', 'citizenship', 'objective', 'Council,', 'basis', 'Follow', 'Find', 'Metro)', '(DC', 'Information', 'zip', 'thorough', 'polygraph', 'issuesincluding', 'science', 'Employers', 'familiar', 'employment', 'Life', '(dual-national', 'mindset', 'premier', 'completion', 'So', 'decisions.', 'Sign', 'research,', 'range', 'Leidos-1', 'analysts,', 'Company', 'scientific', 'CIA', 'policymakers', 'school', 'Thousands', 'comprehensive', 'dynamic', 'Science', 'Salaries', 'drugs', 'Source', 'Intern', 'sometimes', 'social,', 'majors', '84', 'problems.', 'Cyber', 'analyze,', 'international', 'all-source', 'developments.', 'Site', 'positions', 'full-time', 'continues,', 'if', '4', 'Physical', 'months', 'Community', 'last', 'technological', 'A', 'ago', 'Government.', \"We're\", 'available', 'timely,', 'Post', 'warfare,', 'political,', 'require', 'become', 'including:', 'CACIWashington,', 'relocation', 'projects.', 'undergraduate', 'insights', 'degree', 'job,', 'events', 'months.', 'fellow,', 'here', 'Resume', 'investigation', 'On', 'medical', 'interview', 'report', 'Directorate', 'Washington,', 'Computer', 'illegal', 'incomplete', 'Info', 'this', 'Inc.Washington,', 'all', 'Economics', 'global', 'Studies', 'exciting', 'Cookies,', 'TechnologyMcLean,', '$21.93', 'GPA', 'environment.', 'studying', 'Analysis', 'Internship/Co-op', 'recommended', 'economic,', 'Terms', '(DA),', '171', 'Job', 'graduation', 'pursuing', 'Inc.-6', 'Learn', 'their', 'teams', 'Upload', 'unclassifiedand', 'senior', 'candidates', 'Security', 'like', 'The', 'Resumes', 'analyzing', 'Allen', 'not', 'write,', 'possibility', 'Reviews', 'policy', 'alongside', 'Sciences', 'permanent', 'Hamilton-2', 'availability', 'jobs', 'more', 'policymakers.', 'those', 'use', 'helps', 'citizens', 'security', 'students,', 'addition', 'analysis', 'contradictory', 'title,', 'National', 'Minimum', '20535', '2019', 'suitable', 'forefront', 'All', 'code', 'Your', 'updates', 'brief', 'unique', 'Get', 'development,', 'internship', 'Advanced', 'Availability', 'school.', 'allows', 'depending', 'HamiltonWashington,', 'See', 'additional', 'before/following', 'opportunities', 'Affairs', 'providing', 'Program', 'search', 'Area', 'Liberal', 'Technology-1', 'CACI-4', 'benefits', 'working', 'considered', 'serve', 'save', 'You', 'CIA,', 'Analysis.', 'meetings', '$20.75', 'Undergraduate', 'Search', 'area.', 'responsibilities,', 'Quantum', 'customers', 'tours', 'technical', 'Dynamics,', 'solve', 'assessments', 'inform', 'do', 'following', 'successfully', '90-day', 'about', 'least', 'ever-changing', 'then', 'lifestyle..', 'complex', 'job', 'be', 'analyze', 'Dynamics', 'President,', 'Offices', 'generally', '...', 'About', '12', 'participating', 'agency', 'exam', 'Privacy', 'background', 'what', 'Jobs', 'used', 'company', 'cyber', 'Help', 'issue', 'To', 'package,', 'state,', 'psychological', 'weapons', 'metro', 'prior', '/', 'programs,', 'graduate', 'they', 'timely', \"isn't\", 'keywords,', 'it', 'military,', 'required', 'Full-time', 'complete:', 'employment,', 'Engineering,', 'student', 'Within', 'find', 'Engineering', 'by', 'as', 'employers', 'such', 'challenging', 'world-altering', 'sourcesclassified', 'tour', 'Let', 'DC', 'Attending', 'applicants', 'day', 'Indeed', 'Central', 'Senior', 'during', 'Other', 'analytic', 'must'}\n"
     ]
    }
   ],
   "source": [
    "with open('job_one_8.txt','r',encoding='utf-8', errors = 'ignore') as job1:\n",
    "    with open('job_two_8.txt','r',encoding='utf-8', errors = 'ignore') as job2:\n",
    "        job1_str =(job1.read())\n",
    "        job2_str =(job2.read())\n",
    "        \n",
    "        job1_set = set(job1_str.split())\n",
    "        job2_set = set(job2_str.split())\n",
    "        \n",
    "        print(job1_set.difference(job2_set)) \n",
    "        \n",
    "        print(job2_set.difference(job1_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "with open('job_one_8.txt','r',encoding='utf-8', errors = 'ignore') as job1:\n",
    "    with open('job_two_8.txt','r',encoding='utf-8', errors = 'ignore') as job2:\n",
    "        job1_str =(job1.read())\n",
    "        job2_str =(job2.read())\n",
    "        print(fuzz.token_sort_ratio(job1_str,job2_str))\n",
    "        print(fuzz.token_sort_ratio(job2_str,job1_str))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
